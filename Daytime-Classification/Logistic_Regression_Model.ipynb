{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Irrelevant: Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../IDMT-Traffic/datasets/df_main.csv\"\n",
    "data = pd.read_csv(path) #data cleaning -> welche Daten nehmen wir, welche nicht? \n",
    "print(data.head(2))\n",
    "print('-'*80)\n",
    "\n",
    "# drop sampleposition, filename, UNnamed:0 columns\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.drop([\"sample_pos\"], axis=1, inplace=True)  \n",
    "data.drop([\"file\"], axis=1, inplace=True)\n",
    "data.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "\n",
    "print(data.head(2))\n",
    "print('-'*80)\n",
    "\n",
    "# amnalyse speed column\n",
    "print(data[\"speed_kmh\"])\n",
    "print('-'*80)\n",
    "data[\"speed_kmh\"] = pd.to_numeric(data[\"speed_kmh\"], errors=\"coerce\")\n",
    "print(data[\"speed_kmh\"].value_counts(dropna=False).sort_index())\n",
    "print('-'*80)\n",
    "\n",
    "# mapping for encoding speed values\n",
    "speed_mapping = {\n",
    "    70.0: 0,\n",
    "    50.0: 1,\n",
    "    30.0: 2,\n",
    "    np.nan: 3  \n",
    "}\n",
    "\n",
    "data[\"speed_kmh_encoded\"] = data[\"speed_kmh\"].map(speed_mapping)\n",
    "\n",
    "print(data[\"speed_kmh_encoded\"].value_counts().sort_index())\n",
    "\n",
    "# Verify no NaN values remain in speed column\n",
    "print(data[\"speed_kmh_encoded\"].isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_background_encoded  date_time_encoded  location_encoded speed_kmh  \\\n",
      "0                      0                  0                 0        30   \n",
      "1                      0                  0                 0        30   \n",
      "\n",
      "   daytime_encoded  weather_encoded  vehicle_encoded  \\\n",
      "0                1                0                1   \n",
      "1                1                0                1   \n",
      "\n",
      "   source_direction_encoded  microphone_encoded  channel_encoded  ...  \\\n",
      "0                         1                   0                0  ...   \n",
      "1                         1                   1                1  ...   \n",
      "\n",
      "   band_27_dB  band_28_dB  band_29_dB  peak_dB_1  peak_freq_1  peak_dB_2  \\\n",
      "0   37.024301   38.508511   35.946349  50.180933    31.622777  49.528332   \n",
      "1   34.516289   34.960402   33.187933  54.903541  1000.000000  53.196406   \n",
      "\n",
      "   peak_freq_2  peak_dB_3  peak_freq_3  octband_dB_mean  \n",
      "0  1000.000000  47.901831   794.328235        42.383307  \n",
      "1   794.328235  51.942355   501.187234        42.050454  \n",
      "\n",
      "[2 rows x 59 columns]\n",
      "--------------------------------------------------------------------------------\n",
      "speed_kmh\n",
      "30     1183\n",
      "50     5054\n",
      "70     2704\n",
      "UNK     420\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------------------------------------\n",
      "speed_kmh_encoded\n",
      "0    2704\n",
      "1    5054\n",
      "2    1183\n",
      "3     420\n",
      "Name: count, dtype: int64\n",
      "[2 0 1 3]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "data_path = '../IDMT-Traffic/datasets/df_main_encoded_only.csv'  \n",
    "df = pd.read_csv(data_path)\n",
    "df = df.drop(columns=['file', 'Unnamed: 0'])\n",
    "print(df.head(2))\n",
    "print('-'*80)\n",
    "print(df[\"speed_kmh\"].value_counts(dropna=False).sort_index())\n",
    "print('-'*80)\n",
    "\n",
    "# mapping for encoding speed values\n",
    "speed_mapping = {\n",
    "    \"70\": 0,\n",
    "    \"50\": 1,\n",
    "    \"30\": 2,\n",
    "    \"UNK\": 3,\n",
    "    np.nan: 3  \n",
    "}\n",
    "\n",
    "df[\"speed_kmh_encoded\"] = df[\"speed_kmh\"].map(speed_mapping)\n",
    "print(df[\"speed_kmh_encoded\"].value_counts().sort_index())\n",
    "print(df[\"speed_kmh_encoded\"].unique())\n",
    "\n",
    "#delete old speed column and place new, encoded speed column\n",
    "df = df.drop(columns=[\"speed_kmh\"])\n",
    "columns = list(df.columns)\n",
    "columns.insert(3, columns.pop(columns.index(\"speed_kmh_encoded\")))\n",
    "df = df[columns]\n",
    "\n",
    "# Verify no NaN values remain \n",
    "print(df.isnull().values.any())\n",
    "\n",
    "df.to_csv('../Daytime-Classification/df_main_encoded_antonia.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Initialization & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'daytime_encoded'  # Zielvariable\n",
    "X = df.drop(columns=[target])  # Features (alle Spalten au√üer 'daytime')\n",
    "y = df[target]  # Zielvariable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Reduzieren des Trainingsdatensatzes auf 200 Instanzen (Probedatensatz)\n",
    "#X_train = X_train[:200]\n",
    "#y_train = y_train[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anton\\anaconda3\\envs\\traffic_noise\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Trainieren des Modells\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersage auf Testdaten\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8996084015663938\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.92      1642\n",
      "           1       0.90      0.86      0.88      1167\n",
      "\n",
      "    accuracy                           0.90      2809\n",
      "   macro avg       0.90      0.89      0.90      2809\n",
      "weighted avg       0.90      0.90      0.90      2809\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1527  115]\n",
      " [ 167 1000]]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print('-'*80)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print('-'*80)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print('-'*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_noise",
   "language": "python",
   "name": "traffic_noise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
