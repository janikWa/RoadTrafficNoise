{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Schritt 1: Korrelationsanalyse und initiale Feature-Selektion ---\n",
    "def remove_highly_correlated_features(df, threshold=0.9):\n",
    "    correlation_matrix = df.corr().abs()\n",
    "    upper_triangle = correlation_matrix.where(\n",
    "        np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    # Finden der hoch korrelierten Features\n",
    "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "    return df.drop(columns=to_drop), to_drop\n",
    "\n",
    "# --- Schritt 2: Modelltraining und Speicherung der wichtigen Features ---\n",
    "def train_and_evaluate(X, y, threshold=0.85):\n",
    "    # Train-Test-Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Modell initialisieren und trainieren\n",
    "    log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Vorhersagen und Metriken\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Extraktion der wichtigen Features\n",
    "    important_features = pd.Series(log_reg.coef_[0], index=X.columns)\n",
    "    important_features = important_features[important_features.abs() > threshold]\n",
    "    return important_features, log_reg\n",
    "\n",
    "# --- Schritt 3: Analyse der wichtigen Features ---\n",
    "def analyze_important_features(df, important_features):\n",
    "    # Korrelationsmatrix fÃ¼r wichtige Features\n",
    "    important_corr = df[important_features.index].corr()\n",
    "    print(\"Correlation Matrix of Important Features:\")\n",
    "    print(important_corr)\n",
    "    return important_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iteration 1 ---\n",
      "Dropped Features due to high correlation: ['band_2_dB', 'band_14_dB', 'band_15_dB', 'band_16_dB', 'band_17_dB', 'band_18_dB', 'band_19_dB', 'band_20_dB', 'band_21_dB', 'band_22_dB', 'band_23_dB', 'band_24_dB', 'band_25_dB', 'band_26_dB', 'band_27_dB', 'band_28_dB', 'band_29_dB', 'peak_dB_2', 'peak_dB_3', 'octband_dB_mean']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anton\\anaconda3\\envs\\traffic_noise\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.893556425774297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1645\n",
      "           1       0.88      0.86      0.87      1164\n",
      "\n",
      "    accuracy                           0.89      2809\n",
      "   macro avg       0.89      0.89      0.89      2809\n",
      "weighted avg       0.89      0.89      0.89      2809\n",
      "\n",
      "Important Features (>|0.85|): ['mfcc_2']\n",
      "Correlation Matrix of Important Features:\n",
      "        mfcc_2\n",
      "mfcc_2     1.0\n",
      "\n",
      "--- Iteration 2 ---\n",
      "Dropped Features due to high correlation: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anton\\anaconda3\\envs\\traffic_noise\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.893556425774297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1645\n",
      "           1       0.88      0.86      0.87      1164\n",
      "\n",
      "    accuracy                           0.89      2809\n",
      "   macro avg       0.89      0.89      0.89      2809\n",
      "weighted avg       0.89      0.89      0.89      2809\n",
      "\n",
      "Important Features (>|0.85|): ['mfcc_2']\n",
      "Correlation Matrix of Important Features:\n",
      "        mfcc_2\n",
      "mfcc_2     1.0\n",
      "\n",
      "--- Iteration 3 ---\n",
      "Dropped Features due to high correlation: []\n",
      "Accuracy: 0.893556425774297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91      1645\n",
      "           1       0.88      0.86      0.87      1164\n",
      "\n",
      "    accuracy                           0.89      2809\n",
      "   macro avg       0.89      0.89      0.89      2809\n",
      "weighted avg       0.89      0.89      0.89      2809\n",
      "\n",
      "Important Features (>|0.85|): ['mfcc_2']\n",
      "Correlation Matrix of Important Features:\n",
      "        mfcc_2\n",
      "mfcc_2     1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anton\\anaconda3\\envs\\traffic_noise\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# --- Anwendung der Pipeline ---\n",
    "# Daten vorbereiten\n",
    "path = '../IDMT-Traffic/datasets/df_main_encoded_only.csv' \n",
    "df = pd.read_csv(path)\n",
    "df = df.drop(columns=['file', 'Unnamed: 0', 'is_background_encoded'])\n",
    "\n",
    "target = 'daytime_encoded'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Initialisierung der Parameter\n",
    "corr_threshold = 0.95\n",
    "coef_threshold = 0.85\n",
    "iterations = 3\n",
    "\n",
    "# Ergebnisse speichern\n",
    "used_features = []\n",
    "current_df = X.copy()\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "\n",
    "    # Schritt 1: Entfernen hoch korrelierter Features\n",
    "    current_df, dropped_features = remove_highly_correlated_features(current_df, threshold=corr_threshold)\n",
    "    print(f\"Dropped Features due to high correlation: {dropped_features}\")\n",
    "\n",
    "    # Schritt 2: Modelltraining und wichtige Features speichern\n",
    "    important_features, model = train_and_evaluate(current_df, y, threshold=coef_threshold)\n",
    "    print(f\"Important Features (>|{coef_threshold}|): {list(important_features.index)}\")\n",
    "\n",
    "    # Schritt 3: Analyse der wichtigen Features\n",
    "    analyze_important_features(df, important_features)\n",
    "\n",
    "    # Speichern der verwendeten Features\n",
    "    used_features.append(list(current_df.columns))\n",
    "    with open(f\"features_iteration_{iteration + 1}.txt\", \"w\") as f:\n",
    "        f.write(f\"Iteration {iteration + 1} Features:\\n\")\n",
    "        f.write(\"\\n\".join(current_df.columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_noise",
   "language": "python",
   "name": "traffic_noise"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
